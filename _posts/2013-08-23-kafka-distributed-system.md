---
layout: post
title: "kafka分布式系统试用"
description: ""
category: kafka
published: true

---
{% include JB/setup %}

简介
====

kafka是一个由linkedin开源的分布式消息系统。既然是分布式，它就拥有高可用性，没有单点故障。同时它具有很高的吞吐量。和许多其他的日志收集系统不同的是，它采用拉的方式进行消息的获取。而scribe等一些消息收集系统都是采用推的方式进行消息的传递。尤其是scribe，要想对消息做一些解析的工作的话，就需要先将消息写入磁盘，然后再通过读取文件的方式将消息都到程序中进行解析。这中间的经过了一次读文件的过程，并且这个过程单个类别是单个文件的，很容易产生性能瓶颈。而kafka系统则没有这样的担忧。另外比较好的一点就是在github上这个系统还是一直在很活跃地更新。当然对于我来说有一点比较遗憾的就是它也是运行在jvm之上的。使用scale语言编写。个人对java的那一系列实在是不熟悉。


实现方式和原理初步
=================

存储方式
--------

kafka采用存文件的方式对消息进行存储，左右的消息都以log的形式存储在相应的目录下面。很多人都会潜意识的认为文件操作都会很慢，但是其实控制好了，文件操作也是可以很快的。kafka就是一个代表。利用磁盘的顺序读和顺序写的优势性质，以及网络发送的零复制等技术。在性能方面非常优秀。


几个概念
--------

消息按照Topic进行存储，也就是说producer每发送一条消息都要有一个Topic。在Topic下可以设置分为多个PARTITION。这些partition会被均匀地分布在各个broker上。broker就是kafka集群中的每一个实例。同时在0.8版本上增加了replica的功能。每个partition可以设置多个replica。当某个broker出现问题的时候，replica就可以用来恢复数据。broker就是Kafka集群的一个节点，在配置kafka启动的配置文件的时候，每个实例都有自己唯一标记的broker ID，当然在一台机器上也可以启动多个实例，最终构成一个集群，但是生产环境上一般都是一台机器上一个实例。这也是保证数据高可用和稳定性的一种设计措施

kafka监控
--------

这也是让我花费挺长时间去探究的问题，不过主要原因应该是我对JAVA的不熟悉的缘故。官方文档有说，使用JMX端口去监控Kafka的运行状态，但是什么是JMX呢，对于我来说，这种概念就类似于一个外部client可以通过这个端口拿到数据的东西，在google中搜索第一个出现的就是这个github项目[kafka-ganglia](https://github.com/adambarthelson/kafka-ganglia),但是我折腾几天还是没有折腾通顺。最后放弃了，后来无意之间发现，原来在启动的配置文件中有一项设置，可以把kafka的运行状态输出在一个CSV文件中。只是默认情况下，这个选项是`false`的。我打开之后，就可以在相应地目录下看到对应的CSV文件了，通过自己写脚本解析这些文件，就可以了解kafka的运行状态了。

总结
====
作为一个消息发布和订阅系统，其本身具有高吞吐量，高稳定性，而对于客户端而言，又是非常方便使用的。可以说如果在保证整套kafka系统稳定运行的情况下。那么对它的使用将是充满想象的。


